{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":31260,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nos.environ[\"HF_HUB_READ_TIMEOUT\"] = \"60\"\nos.environ[\"HF_HUB_CONNECT_TIMEOUT\"] = \"60\"\nfrom datasets import load_dataset","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2026-01-17T12:42:14.531262Z","iopub.execute_input":"2026-01-17T12:42:14.531835Z","iopub.status.idle":"2026-01-17T12:42:21.117297Z","shell.execute_reply.started":"2026-01-17T12:42:14.531806Z","shell.execute_reply":"2026-01-17T12:42:21.116490Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_dataset = load_dataset('slegroux/tiny-imagenet-200-clean', split='train')                \nvalid_dataset = load_dataset('slegroux/tiny-imagenet-200-clean', split='validation')\ntest_dataset = load_dataset('slegroux/tiny-imagenet-200-clean', split='test')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-17T12:42:21.118745Z","iopub.execute_input":"2026-01-17T12:42:21.119597Z","iopub.status.idle":"2026-01-17T12:42:37.081115Z","shell.execute_reply.started":"2026-01-17T12:42:21.119555Z","shell.execute_reply":"2026-01-17T12:42:37.080477Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom collections import OrderedDict\nimport torch.nn.functional as F\nfrom torchvision import transforms\nfrom torch.utils.data import Dataset, DataLoader, random_split","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-17T12:42:37.081927Z","iopub.execute_input":"2026-01-17T12:42:37.082387Z","iopub.status.idle":"2026-01-17T12:42:40.414840Z","shell.execute_reply.started":"2026-01-17T12:42:37.082353Z","shell.execute_reply":"2026-01-17T12:42:40.414262Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class TransitionLayer(nn.Sequential):\n    def __init__(self, num_input_features, num_output_features):\n        super(TransitionLayer, self).__init__()\n        \n        self.add_module('bn', nn.BatchNorm2d(num_input_features))\n        self.add_module('relu', nn.ReLU(inplace=True))\n        self.add_module('conv1', nn.Conv2d(num_input_features,\n                                          num_output_features, \n                                          kernel_size=(1,1), bias=False))\n        self.add_module('avgpool', nn.AvgPool2d(kernel_size=(2,2), stride=2))\n\nclass DenseLayer(nn.Module):\n    def __init__(self, num_input_features, growth_rate, drop_out=0.0):\n        super(DenseLayer, self).__init__()\n        # BottleNeck Function\n        self.add_module('bn1', nn.BatchNorm2d(num_input_features))\n        self.add_module('relu1', nn.ReLU(inplace=True))\n        self.add_module('conv1', nn.Conv2d(num_input_features, 4*growth_rate, kernel_size=(1,1), bias=False))\n        self.add_module('bn2', nn.BatchNorm2d(4*growth_rate))\n        self.add_module('relu2', nn.ReLU(inplace=True))\n        self.add_module('conv2', nn.Conv2d(4*growth_rate, growth_rate, kernel_size=(3,3), padding=1, bias=False)) # padding = (kernel_size - 1) / 2       \n        \n        self.drop_rate = float(drop_out)\n    def forward(self, x):\n        if isinstance(x, torch.Tensor):\n            prev_features = x\n        else:\n            prev_features = torch.cat(x, 1)\n\n        output_features = self.conv1(self.relu1(self.bn1(prev_features)))\n        output_features = self.conv2(self.relu2(self.bn2(output_features)))\n        if self.drop_rate > 0:\n            output_features = F.dropout(output_features, p=self.drop_rate, \n                                    training=self.training)\n        return output_features\n\n\n\nclass DenseBlock(nn.ModuleDict):\n    def __init__(self, num_input_features, num_layers, growth_rate, drop_out):\n        super(DenseBlock, self).__init__()\n\n        for i in range(num_layers):\n            layer = DenseLayer(num_input_features + i * growth_rate, growth_rate, drop_out)\n            self.add_module('denselayer%d' % (i + 1), layer)\n\n    def forward(self, x):\n        # Need to concatenate every output\n        features = [x]\n        for name, layer in self.items():\n            new_features = layer(features)\n            features.append(new_features)\n        return torch.cat(features, 1)\n            \n\nclass DenseNet(nn.Module):\n    def __init__(self, growth_rate, drop_out, \n                 block_config=(32,16,8), num_classes = 1000):\n        super(DenseNet, self).__init__()\n        init_features = 2 * growth_rate\n        # self.features = nn.Sequential(OrderedDict([\n        #     ('conv0', nn.Conv2d(3, init_features, kernel_size=7, stride=2, padding=3, bias=False)),\n        #     ('norm0', nn.BatchNorm2d(init_features)),\n        #     ('relu0', nn.ReLU(inplace=True)),\n        #     ('pool0', nn.MaxPool2d(kernel_size=3, stride=2, padding=1)),\n        # ]))\n        self.features = nn.Sequential(OrderedDict([\n            ('conv0', nn.Conv2d(3, init_features, kernel_size=3, stride=1, padding=1, bias=False)),\n            ('norm0', nn.BatchNorm2d(init_features)),\n            ('relu0', nn.ReLU(inplace=True)),\n        ]))\n\n        \n        num_features = init_features\n        for i, num_layers in enumerate(block_config):\n            block = DenseBlock(num_layers=num_layers, num_input_features=num_features, \n                              growth_rate=growth_rate, \n                              drop_out=drop_out)\n            self.features.add_module('denseblock%d' % (i + 1), block)\n            num_features = num_features + (num_layers) * growth_rate\n            if i != len(block_config) - 1:\n                # Add transition layer between denseblocks to downsample\n                transition = TransitionLayer(num_features, num_features//2)\n                self.features.add_module('transition%d'%(i+1), transition)\n                num_features = num_features // 2\n\n        self.features.add_module('norm_last', nn.BatchNorm2d(num_features))\n        # Classifier\n        self.classifier = nn.Linear(num_features, num_classes)\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                nn.init.kaiming_normal_(m.weight)\n            elif isinstance(m, nn.BatchNorm2d):\n                nn.init.constant_(m.weight, 1)\n                nn.init.constant_(m.bias, 0)\n            elif isinstance(m, nn.Linear):\n                nn.init.constant_(m.bias, 0)\n\n    \n    def forward(self, x):\n        features = self.features(x)\n        out = F.relu(features, inplace=True)\n        out = F.adaptive_avg_pool2d(out, (1, 1))\n        out = torch.flatten(out, 1)\n        out = self.classifier(out)\n        return out\n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-17T12:46:20.402786Z","iopub.execute_input":"2026-01-17T12:46:20.403121Z","iopub.status.idle":"2026-01-17T12:46:20.418776Z","shell.execute_reply.started":"2026-01-17T12:46:20.403088Z","shell.execute_reply":"2026-01-17T12:46:20.418132Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-17T12:46:20.725323Z","iopub.execute_input":"2026-01-17T12:46:20.725608Z","iopub.status.idle":"2026-01-17T12:46:20.729701Z","shell.execute_reply.started":"2026-01-17T12:46:20.725583Z","shell.execute_reply":"2026-01-17T12:46:20.729015Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"device","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-17T12:46:22.484295Z","iopub.execute_input":"2026-01-17T12:46:22.484866Z","iopub.status.idle":"2026-01-17T12:46:22.489682Z","shell.execute_reply.started":"2026-01-17T12:46:22.484837Z","shell.execute_reply":"2026-01-17T12:46:22.488966Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = DenseNet(\n    growth_rate=12,\n    drop_out=0.0,\n    block_config=(12, 12, 12),\n    num_classes=200   # Tiny-ImageNet\n).to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-17T12:46:23.978107Z","iopub.execute_input":"2026-01-17T12:46:23.978832Z","iopub.status.idle":"2026-01-17T12:46:24.017738Z","shell.execute_reply.started":"2026-01-17T12:46:23.978798Z","shell.execute_reply":"2026-01-17T12:46:24.017214Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"transform = transforms.Compose([\n    transforms.RandomCrop(64, padding=4),\n    transforms.RandomHorizontalFlip(),\n    transforms.ToTensor(),\n    transforms.Normalize(\n        mean=[0.485, 0.456, 0.406],\n        std=[0.229, 0.224, 0.225]\n    )\n])\n\ntest_transform = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize(\n        mean=[0.485, 0.456, 0.406],\n        std=[0.229, 0.224, 0.225]\n    )\n])\n\n\ndef preprocess(example, transform):\n    example[\"image\"] = [transform(img) for img in example[\"image\"]]\n    return example\n\ntrain_dataset = train_dataset.with_transform(lambda x: preprocess(x, transform))\nvalid_dataset = valid_dataset.with_transform(lambda x: preprocess(x, test_transform))\ntest_dataset = test_dataset.with_transform(lambda x: preprocess(x, test_transform))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-17T12:46:52.580858Z","iopub.execute_input":"2026-01-17T12:46:52.581482Z","iopub.status.idle":"2026-01-17T12:46:52.596375Z","shell.execute_reply.started":"2026-01-17T12:46:52.581450Z","shell.execute_reply":"2026-01-17T12:46:52.595764Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"optimizer = torch.optim.SGD(\n            model.parameters(),\n            lr=0.1,\n            momentum=0.9,\n            weight_decay=1e-4,\n            nesterov=True\n        )\n\ntrain_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=4)\nval_loader   = DataLoader(valid_dataset, batch_size=64, shuffle=False, num_workers=4)\ntest_loader   = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=4)\n\nscheduler = torch.optim.lr_scheduler.MultiStepLR(\n    optimizer,\n    milestones=[30, 60, 120],\n    gamma=0.1\n)\ncriterion = nn.CrossEntropyLoss()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-17T12:46:55.312366Z","iopub.execute_input":"2026-01-17T12:46:55.312634Z","iopub.status.idle":"2026-01-17T12:46:55.319118Z","shell.execute_reply.started":"2026-01-17T12:46:55.312611Z","shell.execute_reply":"2026-01-17T12:46:55.318394Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def train_one_epoch(model, dataloader, optimizer, criterion, device):\n    model.train()\n    running_loss = 0.0\n    correct = 0\n    total = 0\n\n    for batch in dataloader:\n        images = batch['image'].to(device)\n        label = batch['label'].to(device)\n\n        # Forward\n        output = model(images)\n        loss = criterion(output, label)\n\n        # Backward\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        # Statistics\n        running_loss += loss.item() * images.size(0)\n        _, preds = output.max(1)\n        correct += preds.eq(label).sum().item()\n        total += label.size(0)\n    epoch_loss = running_loss / total\n    epoch_acc = correct / total\n    return epoch_loss, epoch_acc\n\n@torch.no_grad()\ndef validate(model, dataloader, criterion, device):\n    model.eval()\n    running_loss = 0.0\n    correct = 0\n    total = 0\n    for batch in dataloader:\n        images = batch['image'].to(device)\n        label = batch['label'].to(device)\n\n        # Forward\n        output = model(images)\n        loss = criterion(output, label)\n        running_loss += loss.item() * images.size(0)\n        _, preds = output.max(1)\n        correct += preds.eq(label).sum().item()\n        total += label.size(0)\n    epoch_loss = running_loss / total\n    epoch_acc = correct / total\n    return epoch_loss, epoch_acc","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-17T12:46:55.668596Z","iopub.execute_input":"2026-01-17T12:46:55.668887Z","iopub.status.idle":"2026-01-17T12:46:55.676078Z","shell.execute_reply.started":"2026-01-17T12:46:55.668860Z","shell.execute_reply":"2026-01-17T12:46:55.675339Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"best_val_acc = 0.0\nnum_epochs = 75\nfor epoch in range(num_epochs):\n    train_loss, train_acc = train_one_epoch(\n        model, train_loader, optimizer, criterion, device\n    )\n\n    val_loss, val_acc = validate(\n        model, val_loader, criterion, device\n    )\n    \n    scheduler.step() \n    # Save best model\n    if val_acc > best_val_acc:\n        best_val_acc = val_acc\n        torch.save(model.state_dict(), \"best_model.pth\")\n\n    print(\n        f\"Epoch [{epoch+1}/{num_epochs}] \"\n        f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f} | \"\n        f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\"\n    )\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-17T12:46:58.366291Z","iopub.execute_input":"2026-01-17T12:46:58.366572Z","execution_failed":"2026-01-17T12:52:48.414Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}