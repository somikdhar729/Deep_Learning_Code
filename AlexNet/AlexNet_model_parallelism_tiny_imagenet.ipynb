{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31234,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# from datasets import load_dataset\n\n# dataset = load_dataset(\n#     \"slegroux/tiny-imagenet-200-clean\",\n#     cache_dir=\"/kaggle/working/hf_cache\"\n# )\n\n# print(dataset)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# import os\n\n# out_root = \"/kaggle/working/tiny-imagenet-200\"\n# os.makedirs(out_root, exist_ok=True)\n\n# for split in dataset:\n#     for i, sample in enumerate(dataset[split]):\n#         label = sample.get(\"label\", \"unknown\")\n\n#         if split == \"test\":\n#             out_dir = os.path.join(out_root, split, \"images\")\n#         else:\n#             out_dir = os.path.join(out_root, split, str(label))\n\n#         os.makedirs(out_dir, exist_ok=True)\n#         sample[\"image\"].save(os.path.join(out_dir, f\"{i}.png\"))\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# working_dir = \"/kaggle/working/tiny-imagenet-200\"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nfrom torchvision import transforms\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torchvision import transforms\nimport matplotlib.pyplot as plt\nfrom torch.utils.data import Dataset, DataLoader, random_split\nimport pandas as pd\nimport os\nfrom sklearn.model_selection import train_test_split\nfrom PIL import Image\nfrom datasets import load_dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T12:03:34.447754Z","iopub.execute_input":"2026-01-04T12:03:34.448245Z","iopub.status.idle":"2026-01-04T12:03:43.570506Z","shell.execute_reply.started":"2026-01-04T12:03:34.448213Z","shell.execute_reply":"2026-01-04T12:03:43.569845Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# class AlexNet(nn.Module):\n#     def __init__(self, num_classes, task='classification'):\n#         super().__init__()\n#         # Only define structure, not computation\n#         self.conv1 = nn.Conv2d(in_channels=3,\n#                                out_channels=96,\n#                                kernel_size=(11,11),\n#                                stride=4\n#                               )\n#         self.conv2 = nn.Conv2d(in_channels=96,\n#                                out_channels=256, \n#                                kernel_size=(5,5),\n#                                padding=2\n#                               )\n#         self.conv3 = nn.Conv2d(in_channels=256,\n#                                out_channels=384,\n#                                kernel_size=(3,3),\n#                                padding=1\n#                               )\n#         self.conv4 = nn.Conv2d(in_channels=384,\n#                                out_channels=384,\n#                                kernel_size=(3,3),\n#                                padding=1\n#                               )\n#         self.conv5 = nn.Conv2d(in_channels=384,\n#                                out_channels=256,\n#                                kernel_size=(3,3),\n#                                padding=1\n#                               )\n#         self.lrn1 = nn.LocalResponseNorm(size=5, k = 2, alpha=1e-4, beta=0.75)\n#         self.lrn2 = nn.LocalResponseNorm(size=5, k = 2, alpha=1e-4, beta=0.75)\n\n#         self.max_pool = nn.MaxPool2d(kernel_size=3, stride=2)\n#         self.relu = nn.ReLU()\n#         self.dropout = nn.Dropout()\n        \n#         self.fc1 = nn.Linear(6*6*256, 4096)\n#         self.fc2 = nn.Linear(4096, 4096)\n#         self.fc3 = nn.Linear(4096, num_classes)\n\n#     def forward(self, x):\n#         x = self.max_pool(self.lrn1(self.relu(self.conv1(x))))\n#         x = self.max_pool(self.lrn2(self.relu(self.conv2(x))))\n#         x = self.relu(self.conv3(x))\n#         x = self.relu(self.conv4(x))\n#         x = self.max_pool(self.relu(self.conv5(x)))\n#         x = self.dropout(self.relu(self.fc1(x.flatten(start_dim=1))))\n#         x = self.dropout(self.relu(self.fc2(x)))\n#         x = self.fc3(x)\n#         return x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T08:57:41.214461Z","iopub.execute_input":"2026-01-04T08:57:41.214900Z","iopub.status.idle":"2026-01-04T08:57:41.223094Z","shell.execute_reply.started":"2026-01-04T08:57:41.214875Z","shell.execute_reply":"2026-01-04T08:57:41.222411Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class AlexNet(nn.Module):\n    def __init__(self, num_classes=1000):\n        super().__init__()\n\n        # Conv1 (GPU 0)\n        self.conv1 = nn.Conv2d(3, 96, 11, stride=4).to(\"cuda:0\")\n        self.lrn1 = nn.LocalResponseNorm(5, k=2, alpha=1e-4, beta=0.75).to(\"cuda:0\")\n\n        # Conv2 (split)\n        self.conv2_gpu0 = nn.Conv2d(48, 128, 5, padding=2).to(\"cuda:0\")\n        self.conv2_gpu1 = nn.Conv2d(48, 128, 5, padding=2).to(\"cuda:1\")\n        \n        self.lrn2_gpu0 = nn.LocalResponseNorm(5, k=2, alpha=1e-4, beta=0.75).to(\"cuda:0\")\n        self.lrn2_gpu1 = nn.LocalResponseNorm(5, k=2, alpha=1e-4, beta=0.75).to(\"cuda:1\")\n\n        # Conv3 (GPU 0)\n        self.conv3 = nn.Conv2d(256, 384, 3, padding=1).to(\"cuda:0\")\n\n        # Conv4 (split)\n        self.conv4_gpu0 = nn. Conv2d(192, 192, 3, padding=1).to(\"cuda:0\")\n        self.conv4_gpu1 = nn.Conv2d(192, 192, 3, padding=1).to(\"cuda:1\")\n\n        # Conv5 (split)\n        self.conv5_gpu0 = nn.Conv2d(192, 128, 3, padding=1).to(\"cuda:0\")\n        self.conv5_gpu1 = nn.Conv2d(192, 128, 3, padding=1).to(\"cuda:1\")\n\n        # FC layers\n        self.fc1_gpu0 = nn.Linear(128 * 6 * 6, 2048).to(\"cuda:0\")\n        self.fc1_gpu1 = nn.Linear(128 * 6 * 6, 2048).to(\"cuda:1\")  # Fixed spacing\n        \n        self.fc2_gpu0 = nn.Linear(2048, 2048).to(\"cuda:0\")\n        self.fc2_gpu1 = nn.Linear(2048, 2048).to(\"cuda:1\")\n        \n        self. fc3 = nn.Linear(4096, num_classes).to(\"cuda:0\")\n        \n        self.dropout = 0.5\n\n    def forward(self, x):\n        # Input starts on GPU 0\n        x = x.to(\"cuda:0\")\n\n        # -------- Conv1 --------\n        x = F. relu(self.conv1(x))\n        x = self.lrn1(x)\n        x = F.max_pool2d(x, kernel_size=3, stride=2)\n\n        # Split channels (96 -> 48 + 48)\n        x0, x1 = torch.chunk(x, 2, dim=1)\n        x1 = x1.to(\"cuda:1\")\n\n        # -------- Conv2 (isolated) --------\n        x0 = F.relu(self.conv2_gpu0(x0))\n        x1 = F.relu(self.conv2_gpu1(x1))\n\n        x0 = self.lrn2_gpu0(x0)\n        x1 = self.lrn2_gpu1(x1)\n\n        x0 = F.max_pool2d(x0, kernel_size=3, stride=2)\n        x1 = F. max_pool2d(x1, kernel_size=3, stride=2)  # Fixed spacing\n\n        # -------- Conv3 (merge) --------\n        x1 = x1.to(\"cuda:0\")\n        x = torch.cat([x0, x1], dim=1)\n        x = F.relu(self.conv3(x))\n\n        # Split again (384 -> 192 + 192)\n        x0, x1 = torch.chunk(x, 2, dim=1)\n        x1 = x1.to(\"cuda:1\")\n\n        # -------- Conv4 --------\n        x0 = F.relu(self.conv4_gpu0(x0))\n        x1 = F.relu(self.conv4_gpu1(x1))\n\n        # -------- Conv5 --------\n        x0 = F.relu(self.conv5_gpu0(x0))\n        x1 = F. relu(self. conv5_gpu1(x1))  # Fixed spacing\n\n        x0 = F.max_pool2d(x0, kernel_size=3, stride=2)\n        x1 = F.max_pool2d(x1, kernel_size=3, stride=2)\n\n        # -------- FC layers --------\n        x0 = x0.flatten(1)\n        x1 = x1.flatten(1)\n\n        # FC1\n        z0 = F. dropout(F.relu(self. fc1_gpu0(x0)), p=self.dropout, training=self.training)\n        z1 = F.dropout(F.relu(self.fc1_gpu1(x1)), p=self.dropout, training=self. training)\n\n        # FC2\n        z0 = F.dropout(F.relu(self.fc2_gpu0(z0)), p=self.dropout, training=self. training)  # Fixed spacing\n        z1 = F.dropout(F.relu(self.fc2_gpu1(z1)), p=self.dropout, training=self.training)\n\n        # Final merge\n        z1 = z1.to(\"cuda:0\")\n        z = torch.cat([z0, z1], dim=1)\n\n        return self.fc3(z)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = AlexNet(num_classes=200)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n# model.to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T08:57:41.223882Z","iopub.execute_input":"2026-01-04T08:57:41.224119Z","iopub.status.idle":"2026-01-04T08:57:41.941675Z","shell.execute_reply.started":"2026-01-04T08:57:41.224098Z","shell.execute_reply":"2026-01-04T08:57:41.941046Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"IMAGENET_EIGVAL = torch.tensor([0.2175, 0.0188, 0.0045])\nIMAGENET_EIGVEC = torch.tensor([\n    [-0.5675,  0.7192,  0.4009],\n    [-0.5808, -0.0045, -0.8140],\n    [-0.5836, -0.6948,  0.4203],\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T11:45:56.874361Z","iopub.execute_input":"2026-01-04T11:45:56.875222Z","iopub.status.idle":"2026-01-04T11:45:56.879756Z","shell.execute_reply.started":"2026-01-04T11:45:56.875189Z","shell.execute_reply":"2026-01-04T11:45:56.878681Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class AlexNetPCAJitter(torch.nn.Module):\n    def __init__(self, eigval, eigvec, alpha_std=0.1):\n        super().__init__()\n        self.eigval = eigval\n        self.eigvec = eigvec\n        self.alpha_std = alpha_std\n\n    def forward(self, img):\n        # img: Tensor (3, H, W) in [0,1]\n        alpha = torch.randn(3) * self.alpha_std\n        rgb_shift = (self.eigvec @ (alpha * self.eigval)).view(3, 1, 1)\n        return img + rgb_shift","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T08:57:41.948399Z","iopub.execute_input":"2026-01-04T08:57:41.948651Z","iopub.status.idle":"2026-01-04T08:57:41.959753Z","shell.execute_reply.started":"2026-01-04T08:57:41.948618Z","shell.execute_reply":"2026-01-04T08:57:41.959052Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nos.environ[\"HF_HUB_READ_TIMEOUT\"] = \"60\"\nos.environ[\"HF_HUB_CONNECT_TIMEOUT\"] = \"60\"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_dataset = load_dataset('slegroux/tiny-imagenet-200-clean', split='train')                \nvalid_dataset = load_dataset('slegroux/tiny-imagenet-200-clean', split='validation')\ntest_dataset = load_dataset('slegroux/tiny-imagenet-200-clean', split='test')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T12:03:43.571757Z","iopub.execute_input":"2026-01-04T12:03:43.572196Z","iopub.status.idle":"2026-01-04T12:03:53.075311Z","shell.execute_reply.started":"2026-01-04T12:03:43.572151Z","shell.execute_reply":"2026-01-04T12:03:53.074474Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"transform = transforms.Compose([\n    transforms.Resize(256),\n    transforms.RandomCrop(227),\n    transforms.RandomHorizontalFlip(),\n    transforms.ToTensor(),\n    AlexNetPCAJitter(IMAGENET_EIGVAL, IMAGENET_EIGVEC),\n    transforms.Normalize(\n        mean=[0.485, 0.456, 0.406],\n        std=[0.229, 0.224, 0.225]\n    )\n])\ntest_transform = transforms.Compose([\n    transforms.Resize(256),\n    transforms.CenterCrop(227),\n    transforms.ToTensor(),\n    transforms.Normalize(\n        mean=[0.485, 0.456, 0.406],\n        std=[0.229, 0.224, 0.225]\n    )\n])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T08:57:52.843350Z","iopub.execute_input":"2026-01-04T08:57:52.843756Z","iopub.status.idle":"2026-01-04T08:57:52.849448Z","shell.execute_reply.started":"2026-01-04T08:57:52.843721Z","shell.execute_reply":"2026-01-04T08:57:52.848677Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def preprocess(example, transform):\n    example[\"image\"] = [transform(img) for img in example[\"image\"]]\n    return example\n\ntrain_dataset = train_dataset.with_transform(lambda x: preprocess(x, transform))\nvalid_dataset = valid_dataset.with_transform(lambda x: preprocess(x, test_transform))\ntest_dataset = test_dataset.with_transform(lambda x: preprocess(x, test_transform))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T12:03:53.076588Z","iopub.execute_input":"2026-01-04T12:03:53.076969Z","iopub.status.idle":"2026-01-04T12:03:53.085885Z","shell.execute_reply.started":"2026-01-04T12:03:53.076936Z","shell.execute_reply":"2026-01-04T12:03:53.085192Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=4)\nval_loader   = DataLoader(valid_dataset, batch_size=128, shuffle=False, num_workers=4)\ntest_loader   = DataLoader(test_dataset, batch_size=128, shuffle=False, num_workers=4)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T08:57:52.893249Z","iopub.execute_input":"2026-01-04T08:57:52.893845Z","iopub.status.idle":"2026-01-04T08:57:52.897296Z","shell.execute_reply.started":"2026-01-04T08:57:52.893823Z","shell.execute_reply":"2026-01-04T08:57:52.896644Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"criterion = nn.CrossEntropyLoss()\noptimizer = optim.SGD(model.parameters(),lr=0.01, momentum=0.9, weight_decay=0.5e-4)\n# num_gpus = torch.cuda.device_count()\n# base_lr = 0.02\n# lr = base_lr * num_gpus   # Scale learning rate for DataParallel\n# optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=5e-5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T09:04:15.130810Z","iopub.execute_input":"2026-01-04T09:04:15.131146Z","iopub.status.idle":"2026-01-04T09:04:15.135895Z","shell.execute_reply.started":"2026-01-04T09:04:15.131114Z","shell.execute_reply":"2026-01-04T09:04:15.135251Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def train_one_epoch(model, dataloader, optimizer, criterion, device):\n    model.train()\n    running_loss = 0.0\n    correct = 0\n    total = 0\n\n    for batch in dataloader:\n        images = batch['image'].to(device)\n        label = batch['label'].to(device)\n\n        # Forward\n        output = model(images)\n        loss = criterion(output, label)\n\n        # Backward\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        # Statistics\n        running_loss += loss.item() * images.size(0)\n        _, preds = output.max(1)\n        correct += preds.eq(label).sum().item()\n        total += label.size(0)\n    epoch_loss = running_loss / total\n    epoch_acc = correct / total\n    return epoch_loss, epoch_acc\n\n@torch.no_grad()\ndef validate(model, dataloader, criterion, device):\n    model.eval()\n    running_loss = 0.0\n    correct = 0\n    total = 0\n\n    for batch in dataloader:\n        images = batch['image'].to(device)\n        label = batch['label'].to(device)\n\n        # Forward\n        output = model(images)\n        loss = criterion(output, label)\n        running_loss += loss.item() * images.size(0)\n        _, preds = output.max(1)\n        correct += preds.eq(label).sum().item()\n        total += label.size(0)\n    epoch_loss = running_loss / total\n    epoch_acc = correct / total\n    return epoch_loss, epoch_acc","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T12:04:10.381580Z","iopub.execute_input":"2026-01-04T12:04:10.381879Z","iopub.status.idle":"2026-01-04T12:04:10.389168Z","shell.execute_reply.started":"2026-01-04T12:04:10.381854Z","shell.execute_reply":"2026-01-04T12:04:10.388463Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def train_one_epoch(model, dataloader, optimizer, criterion, device):\n    model.train()\n    running_loss = 0.0\n    correct = 0\n    total = 0\n\n    for batch in dataloader:\n        \n        images = batch['image'].to(\"cuda:0\")\n        label = batch['label'].to(\"cuda:0\")\n\n        # Forward\n        output = model(images)\n        loss = criterion(output, label)\n\n        # Backward\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        # Statistics\n        running_loss += loss.item() * images.size(0)\n        _, preds = output.max(1)\n        correct += preds.eq(label).sum().item()\n        total += label.size(0)\n    epoch_loss = running_loss / total\n    epoch_acc = correct / total\n    return epoch_loss, epoch_acc\n\n@torch.no_grad()\ndef validate(model, dataloader, criterion, device):\n    model.eval()\n    running_loss = 0.0\n    correct = 0\n    total = 0\n\n    for batch in dataloader:\n        images = batch['image'].to(\"cuda:0\")\n        label = batch['label'].to(\"cuda:0\")\n\n        # Forward\n        output = model(images)\n        loss = criterion(output, label)\n        running_loss += loss.item() * images.size(0)\n        _, preds = output.max(1)\n        correct += preds.eq(label).sum().item()\n        total += label.size(0)\n    epoch_loss = running_loss / total\n    epoch_acc = correct / total\n    return epoch_loss, epoch_acc","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"best_val_acc = 0.0\nnum_epochs = 40\nfor epoch in range(num_epochs):\n    train_loss, train_acc = train_one_epoch(\n        model, train_loader, optimizer, criterion, device\n    )\n\n    val_loss, val_acc = validate(\n        model, val_loader, criterion, device\n    )\n\n    # Save best model\n    if val_acc > best_val_acc:\n        best_val_acc = val_acc\n        torch.save(model.state_dict(), \"best_model.pth\")\n\n    print(\n        f\"Epoch [{epoch+1}/{num_epochs}] \"\n        f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f} | \"\n        f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\"\n    )\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T09:04:19.374124Z","iopub.execute_input":"2026-01-04T09:04:19.375079Z","execution_failed":"2026-01-04T11:33:48.859Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# ResNet Architectures","metadata":{}},{"cell_type":"code","source":"# class BasicBlock(nn.Module):\n#     expansion = 1\n#     def __init__(self, in_channels, out_channels, stride=1, downsample=None):\n#         super().__init__()\n#         self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n#         self.bn1 = nn.BatchNorm2d(out_channels)\n#         self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n#         self.bn2 = nn.BatchNorm2d(out_channels)\n#         self.relu = nn.ReLU(inplace=True)\n\n#         self.downsample = downsample\n#         self.strdide = stride\n\n#     def forward(self, x):\n#         identity = x\n#         out = self.relu(self.bn1(self.conv1(x)))\n#         out = self.bn2(self.conv2(out))\n#         if self.downsample is not None:\n#             identity = self.downsample(x)\n#         out += identity\n#         out = self.relu(out)\n#         return out","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T12:03:55.048694Z","iopub.execute_input":"2026-01-04T12:03:55.049329Z","iopub.status.idle":"2026-01-04T12:03:55.055290Z","shell.execute_reply.started":"2026-01-04T12:03:55.049300Z","shell.execute_reply":"2026-01-04T12:03:55.054457Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# class ResNet34(nn.Module):\n#     def __init__(self, num_classes=1000):\n#         super().__init__()\n#         self.in_channels = 64\n\n#         # Initial layers\n#         self.conv1 = nn.Conv2d(3,64, kernel_size=7, stride=2, padding=3, bias=False)\n#         self.bn1 = nn.BatchNorm2d(64)\n#         self.relu = nn.ReLU(inplace=True)\n#         self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n\n#         # Stage 1: 3 Blocks, 64 channels\n#         self.layer1 = self._make_layer(64,3, stride=1)\n#         # Stage 2: 4 blocks, 128 channels\n#         self.layer2 = self._make_layer(128, 4, stride=2)\n#         # Stage 3: 6 blocks, 256 channels\n#         self.layer3 = self._make_layer(256, 6, stride=2)\n#         # Stage 4: 3 blocks, 512 channels\n#         self.layer4 = self._make_layer(512, 3, stride=2)\n\n#         self.avgpool = nn.AdaptiveAvgPool2d((1,1))\n#         self.fc = nn.Linear(512 * BasicBlock.expansion, num_classes)\n\n#     def _make_layer(self, out_channels, blocks, stride):\n#         downsample = None\n\n#         if stride != 1 or self.in_channels != out_channels * BasicBlock.expansion:\n#             downsample = nn.Sequential(nn.Conv2d(self.in_channels, out_channels * BasicBlock.expansion, kernel_size=1, stride=stride, bias=False),\n#                                       nn.BatchNorm2d(out_channels*BasicBlock.expansion)\n#                                       )\n#         layers = []\n#         layers.append(BasicBlock(self.in_channels, out_channels, stride, downsample))\n\n#         self.in_channels = out_channels * BasicBlock.expansion\n#         for _ in range(1, blocks):\n#             layers.append(BasicBlock(self.in_channels, out_channels))\n#         return nn.Sequential(*layers)\n\n#     def forward(self, x):\n#         x = self.relu(self.bn1(self.conv1(x)))\n#         x = self.maxpool(x)\n#         x = self.layer1(x)\n#         x = self.layer2(x)\n#         x = self.layer3(x)\n#         x = self.layer4(x)\n        \n#         x = self.avgpool(x)\n#         x = torch.flatten(x, 1)\n#         x = self.fc(x)\n        \n#         return x\n\n            \n            ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T12:03:56.975621Z","iopub.execute_input":"2026-01-04T12:03:56.975925Z","iopub.status.idle":"2026-01-04T12:03:56.985582Z","shell.execute_reply.started":"2026-01-04T12:03:56.975899Z","shell.execute_reply":"2026-01-04T12:03:56.984852Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# class Bottleneck(nn.Module):\n#     expansion = 4\n\n#     def __init__(self, in_channels, out_channels, stride=1, downsample=None):\n#         super().__init__()\n\n#         self.conv1 = nn.Conv2d(\n#             in_channels, out_channels,\n#             kernel_size=1, stride=1, padding=0, bias=False\n#         )\n#         self.bn1 = nn.BatchNorm2d(out_channels)\n\n#         # STRIDE GOES HERE\n#         self.conv2 = nn.Conv2d(\n#             out_channels, out_channels,\n#             kernel_size=3, stride=stride, padding=1, bias=False\n#         )\n#         self.bn2 = nn.BatchNorm2d(out_channels)\n\n#         self.conv3 = nn.Conv2d(\n#             out_channels, out_channels * self.expansion,\n#             kernel_size=1, stride=1, padding=0, bias=False\n#         )\n#         self.bn3 = nn.BatchNorm2d(out_channels * self.expansion)\n\n#         self.relu = nn.ReLU(inplace=True)\n#         self.downsample = downsample\n\n#     def forward(self, x):\n#         identity = x\n\n#         out = self.relu(self.bn1(self.conv1(x)))\n#         out = self.relu(self.bn2(self.conv2(out)))\n#         out = self.bn3(self.conv3(out))\n\n#         if self.downsample is not None:\n#             identity = self.downsample(x)\n\n#         out += identity\n#         out = self.relu(out)\n#         return out\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# class ResNet50(nn.Module):\n#     def __init__(self, num_classes=1000):\n#         super().__init__()\n#         self.in_channels = 64\n\n#         # Initial layers\n#         self.conv1 = nn.Conv2d(3,64, kernel_size=7, stride=2, padding=3, bias=False)\n#         self.bn1 = nn.BatchNorm2d(64)\n#         self.relu = nn.ReLU(inplace=True)\n#         self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n\n#         # Stage 1: 3 Blocks, 64 channels\n#         self.layer1 = self._make_layer(64,3, stride=1)\n#         # Stage 2: 4 blocks, 128 channels\n#         self.layer2 = self._make_layer(128, 4, stride=2)\n#         # Stage 3: 6 blocks, 256 channels\n#         self.layer3 = self._make_layer(256, 6, stride=2)\n#         # Stage 4: 3 blocks, 512 channels\n#         self.layer4 = self._make_layer(512, 3, stride=2)\n\n#         self.avgpool = nn.AdaptiveAvgPool2d((1,1))\n#         self.fc = nn.Linear(512 * Bottleneck.expansion, num_classes)\n\n#     def _make_layer(self, out_channels, blocks, stride):\n#         downsample = None\n\n#         if stride != 1 or self.in_channels != out_channels * Bottleneck.expansion:\n#             downsample = nn.Sequential(nn.Conv2d(self.in_channels, out_channels * Bottleneck.expansion, kernel_size=1, stride=stride, bias=False),\n#                                       nn.BatchNorm2d(out_channels*Bottleneck.expansion)\n#                                       )\n#         layers = []\n#         layers.append(Bottleneck(self.in_channels, out_channels, stride, downsample))\n\n#         self.in_channels = out_channels * Bottleneck.expansion\n#         for _ in range(1, blocks):\n#             layers.append(Bottleneck(self.in_channels, out_channels))\n#         return nn.Sequential(*layers)\n\n#     def forward(self, x):\n#         x = self.relu(self.bn1(self.conv1(x)))\n#         x = self.maxpool(x)\n#         x = self.layer1(x)\n#         x = self.layer2(x)\n#         x = self.layer3(x)\n#         x = self.layer4(x)\n        \n#         x = self.avgpool(x)\n#         x = torch.flatten(x, 1)\n#         x = self.fc(x)\n        \n#         return x\n\n            \n            ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# transform = transforms.Compose([\n#     transforms.Resize(256),\n#     transforms.RandomCrop(224),\n#     transforms.RandomHorizontalFlip(),\n#     transforms.ToTensor(),\n#     # AlexNetPCAJitter(IMAGENET_EIGVAL, IMAGENET_EIGVEC),\n#     transforms.Normalize(\n#         mean=[0.485, 0.456, 0.406],\n#         std=[0.229, 0.224, 0.225]\n#     )\n# ])\n# test_transform = transforms.Compose([\n#     transforms.Resize(256),\n#     transforms.CenterCrop(224),\n#     transforms.ToTensor(),\n#     transforms.Normalize(\n#         mean=[0.485, 0.456, 0.406],\n#         std=[0.229, 0.224, 0.225]\n#     )\n# ])\n\n# def preprocess(example, transform):\n#     example[\"image\"] = [transform(img) for img in example[\"image\"]]\n#     return example\n\n# train_dataset = train_dataset.with_transform(lambda x: preprocess(x, transform))\n# valid_dataset = valid_dataset.with_transform(lambda x: preprocess(x, test_transform))\n# test_dataset = test_dataset.with_transform(lambda x: preprocess(x, test_transform))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T12:03:59.162521Z","iopub.execute_input":"2026-01-04T12:03:59.162810Z","iopub.status.idle":"2026-01-04T12:03:59.178710Z","shell.execute_reply.started":"2026-01-04T12:03:59.162786Z","shell.execute_reply":"2026-01-04T12:03:59.178034Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # del model, optimizer\n# # torch.cuda.empty_cache()\n# model_resnet50 = ResNet50(num_classes=200)\n# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n# model_resnet50.to(device)\n# criterion = nn.CrossEntropyLoss()\n# optimizer = optim.SGD(model_resnet50.parameters(),lr=0.01, momentum=0.9, weight_decay=0.5e-4)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T12:04:01.498530Z","iopub.execute_input":"2026-01-04T12:04:01.498824Z","iopub.status.idle":"2026-01-04T12:04:01.886375Z","shell.execute_reply.started":"2026-01-04T12:04:01.498800Z","shell.execute_reply":"2026-01-04T12:04:01.885578Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=4)\n# val_loader   = DataLoader(valid_dataset, batch_size=64, shuffle=False, num_workers=4)\n# test_loader   = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=4)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T12:04:02.382299Z","iopub.execute_input":"2026-01-04T12:04:02.382602Z","iopub.status.idle":"2026-01-04T12:04:02.387039Z","shell.execute_reply.started":"2026-01-04T12:04:02.382578Z","shell.execute_reply":"2026-01-04T12:04:02.386346Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# best_val_acc = 0.0\n# num_epochs = 40\n# for epoch in range(num_epochs):\n#     train_loss, train_acc = train_one_epoch(\n#         model_resnet50, train_loader, optimizer, criterion, device\n#     )\n\n#     val_loss, val_acc = validate(\n#         model_resnet50, val_loader, criterion, device\n#     )\n\n#     # Save best model\n#     if val_acc > best_val_acc:\n#         best_val_acc = val_acc\n#         torch.save(model_resnet50.state_dict(), \"best_model_resnet34.pth\")\n\n#     print(\n#         f\"Epoch [{epoch+1}/{num_epochs}] \"\n#         f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f} | \"\n#         f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\"\n#     )\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T12:09:24.016339Z","iopub.execute_input":"2026-01-04T12:09:24.017118Z","execution_failed":"2026-01-04T14:01:15.243Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"_, test_acc = validate( model, test_loader, criterion, device)\nprint(test_acc)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}